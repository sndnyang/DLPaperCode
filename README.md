# DLPaperCode

Trial and Error of Deep Learning Paper's reproduce or hyperparameter setting

## 1. One Cycle Learning Rate

《Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates》

Paper: https://arxiv.org/abs/1708.07120 

Conclusion:

1/10 - 1/5 training time, but 3%-5% accuracy drops -- constant learning rate with decaying may also achieve this.

Almost failed, Because the baseline is weak, their results are better than a very weak baseline. 
